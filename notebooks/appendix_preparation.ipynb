{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix - Code Assiting Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README\n",
    "\n",
    "TBC-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Initial Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell every time you start a new kernel to configure related parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "curr_root = Path().resolve()    # current file path\n",
    "repo_root = curr_root.parent    # current repository path\n",
    "data_root = repo_root / \"data\"  # path for saving the data\n",
    "src_root = repo_root / \"src\"    # path for other sources\n",
    "sys.path.append(str(src_root))  # add src to system path to import custom functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data Download Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 NO2 Data Download "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, NO2 pollution data from [Google Earth Engine Sentinel 5P](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S5P_NRTI_L3_NO2) is downloaded, for both Ethiopia and Iraq in country level.\n",
    "\n",
    "From related literature and data quality, we finally decided to use **NO2_column_number_density** as the proxy for NO2 concentration level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom function to generate desired time period of NOx data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "import ee\n",
    "ee.Authenticate() # For the first Initialization, individual API is needed to log into Google Earth Engine\n",
    "ee.Initialize()\n",
    "\n",
    "# Function: generate desired time period of NO2 data  \n",
    "def specific_date(start_date: str, end_date: str, time_resolution: str = 'D') -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate a list of dates within specified time period and resolution.\n",
    "\n",
    "    Parameters:\n",
    "    - start_date: str\n",
    "        Start date, format: 'YYYY-MM-DD'.\n",
    "    - end_date: str\n",
    "        End date, format: 'YYYY-MM-DD'.\n",
    "    - time_resolution: str\n",
    "        Time resolution (e.g., 'D' for daily, 'W' for weekly, 'M' for monthly). Default is 'D'.\n",
    "    \n",
    "    Return:\n",
    "    - dates(list): List of date strings marking the ends of each time segment, format: 'YYYY-MM-DD'.\n",
    "    \n",
    "    \"\"\"\n",
    "    dates = (\n",
    "        pd.date_range(start_date, end_date, freq = time_resolution)\n",
    "        .strftime('%Y-%m-%d')\n",
    "        .tolist()\n",
    "    )\n",
    "    return dates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request tasks to download in Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: download NO2 data\n",
    "def download_no2_country(country_name: str, dates: list):\n",
    "    \"\"\"\n",
    "    Request NO2 data download from Earth Engine for a specified country and time period\n",
    "\n",
    "    Parameters:\n",
    "    - country_name: str\n",
    "        Name of the target country. Must match the format used by Earth Engine.\n",
    "    - dates: list\n",
    "        List containing the desired time range, (e.g., [start_date, end_date]).\n",
    "\n",
    "    Return:\n",
    "    - None. Sends a/multiple request(s) to Earth Engine to initiate data download.\n",
    "        Exported files are saved under a folder named 'NO2_<country_name>' in first-level Google Drive directory.\n",
    "        Each exported .tiff file is named using its starting date.\n",
    "    \"\"\"\n",
    "    \n",
    "    countries = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n",
    "    country = countries.filter(ee.Filter.eq('country_na', country_name)).geometry()\n",
    "\n",
    "    n_dates = len(dates)\n",
    "\n",
    "    for i in range(n_dates-1):\n",
    "\n",
    "        date_start, date_end = dates[i], dates[i+1]\n",
    "\n",
    "        no2 = (ee.ImageCollection('COPERNICUS/S5P/NRTI/L3_NO2')\n",
    "            .select('tropospheric_NO2_column_number_density')\n",
    "            .filterDate(date_start, date_end)\n",
    "            .mean())\n",
    "\n",
    "        task = ee.batch.Export.image.toDrive(\n",
    "            image=no2,\n",
    "            description=f'{country_name}_NO2_{date_start}_{date_end}',\n",
    "            folder=f'NO2_{country_name}',\n",
    "            fileNamePrefix=f'{country_name}_NO2_{date_start}',\n",
    "            region=country,\n",
    "            scale=1000,\n",
    "            maxPixels=1e13\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            task.start()\n",
    "            print(f'{country_name}: The export task for {date_start} is ongoing, please check the results in Google Drive.')\n",
    "        except Exception as e:\n",
    "            print(f'Fail to submit task: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Call and Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = specific_date('2023-01-01', '2025-01-01')\n",
    "len(dates) # 731\n",
    "\n",
    "# Download Ethiopia Data\n",
    "download_no2_country('Ethiopia', dates)\n",
    "\n",
    "# Download Iraq Data\n",
    "download_no2_country('Iraq', dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Other Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Generate Meshes for filling features\n",
    "\n",
    "Generate meshes, from 2023-01-01 to 2024-12-31, one mesh for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Generating meshes for Addis Ababa!\n",
      "Complete Generating meshes for Baghdad!\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "import fiona\n",
    "\n",
    "mesh_addis = data_root / \"mesh-grid\" / \"grid_addis_ababa.gpkg\"\n",
    "mesh_baghdad = data_root / \"mesh-grid\" / \"grid_baghdad.gpkg\"\n",
    "\n",
    "lyr_addis_name = fiona.listlayers(mesh_addis)[0]  # control layer number\n",
    "lyr_baghdad_name = fiona.listlayers(mesh_baghdad)[0]\n",
    "\n",
    "# start and end date\n",
    "start_date = datetime.strptime(\"2023-01-01\", \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(\"2024-12-31\", \"%Y-%m-%d\")\n",
    "\n",
    "addis_meshes_path = data_root / 'addis-empty-mesh-data'\n",
    "baghdad_meshes_path = data_root / 'baghdad-empty-mesh-data'\n",
    "\n",
    "addis_meshes_path.mkdir(exist_ok=True)\n",
    "baghdad_meshes_path.mkdir(exist_ok=True)\n",
    "\n",
    "delta = end_date - start_date\n",
    "days_count = delta.days + 1\n",
    "\n",
    "# For Addis Ababa\n",
    "for i in range(days_count):\n",
    "    current_date = start_date + timedelta(days=i)\n",
    "    date_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "    filename = f\"addis-ababa-{date_str}.gpkg\"\n",
    "    dest_path = addis_meshes_path / filename\n",
    "\n",
    "    shutil.copy(mesh_addis, dest_path)\n",
    "\n",
    "print(f\"Complete Generating meshes for Addis Ababa!\")\n",
    "\n",
    "# For Baghdad\n",
    "for i in range(days_count):\n",
    "    current_date = start_date + timedelta(days=i)\n",
    "    date_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "    filename = f\"baghdad-{date_str}.gpkg\"\n",
    "    dest_path = baghdad_meshes_path / filename\n",
    "\n",
    "    shutil.copy(mesh_baghdad, dest_path)\n",
    "\n",
    "\n",
    "print(f\"Complete Generating meshes for Baghdad!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generate Date Tables for Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date    Weekday Ethiopia_Workday_Type Iraq_Workday_Type\n",
      "0 2023-01-01     Sunday              Weekends           Thu-Sun\n",
      "1 2023-01-02     Monday              Workdays       Mon-Tue-Wed\n",
      "2 2023-01-03    Tuesday              Workdays       Mon-Tue-Wed\n",
      "3 2023-01-04  Wednesday              Workdays       Mon-Tue-Wed\n",
      "4 2023-01-05   Thursday              Workdays           Thu-Sun\n",
      "5 2023-01-06     Friday              Workdays           Fri-Sat\n",
      "6 2023-01-07   Saturday              Weekends           Fri-Sat\n",
      "7 2023-01-08     Sunday              Weekends           Thu-Sun\n",
      "8 2023-01-09     Monday              Workdays       Mon-Tue-Wed\n",
      "9 2023-01-10    Tuesday              Workdays       Mon-Tue-Wed\n"
     ]
    }
   ],
   "source": [
    "# Generate Standard Date Table\n",
    "import pandas as pd\n",
    "\n",
    "# Generate date range\n",
    "date_range = pd.date_range(start='2023-01-01', end='2024-12-31', freq='D')\n",
    "df = pd.DataFrame({'Date': date_range})\n",
    "df['Weekday'] = df['Date'].dt.day_name()\n",
    "\n",
    "# Define Ethiopia workday type: \n",
    "# Mon-Fri -> \"Workdays\", Sat-Sun -> \"Weekends\"\n",
    "df['Ethiopia_Workday_Type'] = df['Weekday'].apply(\n",
    "    lambda x: \"Workdays\" if x in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'] else \"Weekends\"\n",
    ")\n",
    "\n",
    "# Define Iraq workday type:\n",
    "# Mon-Tue-Wed -> 'Mon-Tue-Wed', Fri-Sat -> 'Fri-Sat', Thu-Sun -> 'Thu-Sun'\n",
    "iraq_workday_type = {\n",
    "    'Monday': 'Mon-Tue-Wed', 'Tuesday': 'Mon-Tue-Wed', 'Wednesday': 'Mon-Tue-Wed',\n",
    "    'Friday': 'Fri-Sat', 'Saturday': 'Fri-Sat',\n",
    "    'Thursday': 'Thu-Sun', 'Sunday': 'Thu-Sun'\n",
    "}\n",
    "df['Iraq_Workday_Type'] = df['Weekday'].map(iraq_workday_type)\n",
    "\n",
    "# Reorder columns\n",
    "df = df[['Date', 'Weekday', 'Ethiopia_Workday_Type', 'Iraq_Workday_Type']]\n",
    "df.to_csv(data_root / 'helper-files' / 'workday_type_2023_2024.csv', index=False, encoding='utf-8-sig')  # save the data if needed\n",
    "\n",
    "# Preview first few rows\n",
    "print(df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
